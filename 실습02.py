import streamlit as st
import openai
import os
import pandas as pd
import random
from langchain.chains import ConversationalRetrievalChain
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.memory import ConversationBufferMemory
from langchain.vectorstores import FAISS
from langchain.schema import Document
from langchain.chat_models import ChatOpenAI

# API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = st.secrets["openai"]["api_key"]

# ì¶”ì²œìš© ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df_games = pd.read_csv('boardgames.csv')
df_cafes = pd.read_csv('cafes.csv')

# RAG ì±—ë´‡ìš© ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df_gameinfo = pd.read_csv('gameinfo.csv')
df_cafeinfo = pd.read_csv('cafeinfo.csv')

# ì´ˆê¸° ìƒíƒœ ì„¤ì •
def init_session_state():
    if "conversation" not in st.session_state:
        st.session_state.conversation = None
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = None
    if "processComplete" not in st.session_state:
        st.session_state.processComplete = None
    if 'messages' not in st.session_state:
        st.session_state['messages'] = [{"role": "assistant", 
                                         "content": "ì•ˆë…•í•˜ì„¸ìš”! ì£¼ì–´ì§„ ë¬¸ì„œì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹  ê²ƒì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë´ì£¼ì„¸ìš”!"}]

# ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
def get_vectorstore(text_chunks):
    documents = [Document(page_content=chunk) for chunk in text_chunks]
    embeddings = HuggingFaceEmbeddings(
        model_name="jhgan/ko-sroberta-multitask",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    vectordb = FAISS.from_documents(documents, embeddings)
    return vectordb

# ëŒ€í™” ì²´ì¸ ìƒì„±
def get_conversation_chain(vetorestore, openai_api_key):
    llm = ChatOpenAI(openai_api_key=openai_api_key, model_name='gpt-3.5-turbo', temperature=0)

    if "chat_memory" not in st.session_state:
        st.session_state.chat_memory = ConversationBufferMemory(
            memory_key='chat_history',
            return_messages=True,
            output_key='answer'
        )

    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        chain_type="stuff",
        retriever=vetorestore.as_retriever(search_type='similarity', verbose=True),
        memory=st.session_state.chat_memory,
        get_chat_history=lambda h: h,
        return_source_documents=True,
        verbose=True
    )
    return conversation_chain

# ë³´ë“œê²Œì„ ì¶”ì²œ í•¨ìˆ˜
def show_recommended_games(genre):
    filtered_games = df_games[df_games['ì¥ë¥´'].str.contains(genre, na=False)]['ê²Œì„ ì´ë¦„'].tolist()
    random.shuffle(filtered_games)
    return filtered_games[:5]

# ë³´ë“œê²Œì„ ì„¤ëª… í•¨ìˆ˜
def get_game_details(game_name):
    game_row = df_gameinfo[df_gameinfo['ë³´ë“œê²Œì„ì´ë¦„'].str.lower() == game_name.lower()]
    if not game_row.empty:
        details = game_row.iloc[0]
        # ì¤„ë°”ê¿ˆ ë¬¸ìë¥¼ <br>ë¡œ ëŒ€ì²´
        game_rules = details['ê²Œì„ê·œì¹™'].replace('\n', '<br>')
        response = (
            f"<strong>ë³´ë“œê²Œì„ ì´ë¦„:</strong> {details['ë³´ë“œê²Œì„ì´ë¦„']}<br>"
            f"<strong>ì¥ë¥´:</strong> {details['ë³´ë“œê²Œì„ì¥ë¥´']}<br>"
            f"<strong>ê°„ëµ ì†Œê°œ:</strong> {details['ë³´ë“œê²Œì„ê°„ëµì†Œê°œ']}<br>"
            f"<strong>í”Œë ˆì´ ì¸ì›ìˆ˜:</strong> {details['ë³´ë“œê²Œì„í”Œë ˆì´ì¸ì›ìˆ˜']}<br>"
            f"<strong>ê²Œì„ ê·œì¹™</strong><br> {game_rules}"  # ê²Œì„ ê·œì¹™ í…ìŠ¤íŠ¸ í›„ ì¤„ë°”ê¿ˆ ì¶”ê°€
        )
        return response
    else:
        return "í•´ë‹¹ ë³´ë“œê²Œì„ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."



# ë³´ë“œê²Œì„ ì¶”ì²œ ì²˜ë¦¬ í•¨ìˆ˜
def handle_game_recommendation_from_csv(query):
    # ì§€ì›í•˜ëŠ” ì¥ë¥´ ëª©ë¡
    genres = ['ë§ˆí”¼ì•„', 'ìˆœë°œë ¥', 'íŒŒí‹°', 'ì „ëµ', 'ì¶”ë¦¬', 'í˜‘ë ¥', 'ì•¡ì…˜']
    
    # ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ ì¥ë¥´ ì°¾ê¸°
    found_genre = None
    for genre in genres:
        if genre in query:
            found_genre = genre
            break

    if found_genre:
        # í•´ë‹¹ ì¥ë¥´ì˜ ë³´ë“œê²Œì„ í•„í„°ë§
        filtered_games = df_gameinfo[df_gameinfo['ë³´ë“œê²Œì„ì¥ë¥´'].str.contains(found_genre, na=False)]['ë³´ë“œê²Œì„ì´ë¦„'].tolist()
        if filtered_games:
            recommended_games = random.sample(filtered_games, min(5, len(filtered_games)))
            recommendation_response = [f"{found_genre} ì¥ë¥´ì˜ ì¶”ì²œ ë³´ë“œê²Œì„ ëª©ë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:"]
            recommendation_response.extend([f"â—¾ {game}" for game in recommended_games])
        else:
            recommendation_response = [f"ì£„ì†¡í•©ë‹ˆë‹¤. {found_genre} ì¥ë¥´ì˜ ë³´ë“œê²Œì„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
    else:
        recommendation_response = ["ì§ˆë¬¸ì— ì–¸ê¸‰ëœ ì¥ë¥´ê°€ ì—†ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ 'ì¶”ë¦¬ ì¥ë¥´ ë³´ë“œê²Œì„ ì¶”ì²œí•´ì¤˜'ì™€ ê°™ì€ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”."]

    return recommendation_response

# ë©”ì¸ í•¨ìˆ˜
def main():
    init_session_state()

    st.markdown("<h1 style='font-size: 24px;'>ë³´ë“œê²Œì„ ì¶”ì²œ ì‹œìŠ¤í…œ</h1>", unsafe_allow_html=True)
    st.markdown("<h2 style='font-size: 18px;'>ì›í•˜ì‹œëŠ” ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:</h2>", unsafe_allow_html=True)

    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("ğŸ² ë³´ë“œê²Œì„ ì¶”ì²œ"):
            st.session_state.service = 'game_recommendation'
    with col2:
        if st.button("ğŸ  ë³´ë“œê²Œì„ ì¹´í˜ ì¶”ì²œ"):
            st.session_state.service = 'cafe_recommendation'
    with col3:
        if st.button("ğŸ§š ë³´ë“œê²Œì„ ìš”ì •ì—ê²Œ ì§ˆë¬¸í•˜ê¸°"):
            st.session_state.service = 'chat_with_fairy'

    if 'service' in st.session_state:
        if st.session_state.service == 'game_recommendation':
            st.markdown("<h3 style='font-size: 20px;'>ì–´ë– í•œ ì¥ë¥´ì˜ ë³´ë“œê²Œì„ì„ ì°¾ìœ¼ì‹œë‚˜ìš”?</h3>", unsafe_allow_html=True)
            genre = st.selectbox("ì¥ë¥´ ì„ íƒ", ['ë§ˆí”¼ì•„', 'ìˆœë°œë ¥', 'íŒŒí‹°', 'ì „ëµ', 'ì¶”ë¦¬', 'í˜‘ë ¥'])
            if genre:
                st.write("ë‹¤ìŒ ë³´ë“œê²Œì„ë“¤ì„ ì¶”ì²œí•©ë‹ˆë‹¤:")
                recommended_games = show_recommended_games(genre)
                st.write("\n".join(recommended_games))

        elif st.session_state.service == 'cafe_recommendation':
            st.markdown("<h3 style='font-size: 20px;'>ì–´ë””ì—ì„œ í•˜ì‹¤ ì˜ˆì •ì¸ê°€ìš”?</h3>", unsafe_allow_html=True)
            location = st.selectbox("ì§€ì—­ ì„ íƒ", ['í™ëŒ€', 'ì‹ ì´Œ', 'ê±´ëŒ€ì…êµ¬', 'ì´ìˆ˜', 'ê°•ë‚¨ì—­', 'ë¶€ì²œ'])
            if location:
                st.write("ë‹¤ìŒ ì¹´í˜ë“¤ì„ ì¶”ì²œí•©ë‹ˆë‹¤:")
                cafes = show_recommended_cafes(location)
                for cafe in cafes:
                    cafe_data = df_cafes[df_cafes['ì¹´í˜ ì´ë¦„'] == cafe].iloc[0]
                    review_count = cafe_data['ë°©ë¬¸ìë¦¬ë·°ìˆ˜']
                    naver_map_url = cafe_data['ë„¤ì´ë²„ì§€ë„ì£¼ì†Œ']
                    st.write(f"- {cafe} (ë°©ë¬¸ìë¦¬ë·°: {review_count}) ")
                    st.markdown(f"[â¡ï¸ ë„¤ì´ë²„ ì§€ë„]({naver_map_url})", unsafe_allow_html=True)

        elif st.session_state.service == 'chat_with_fairy':
            st.markdown("<h3 style='font-size: 20px;'>ë³´ë“œê²Œì„ ìš”ì •ì—ê²Œ ì§ˆë¬¸í•˜ê¸°</h3>", unsafe_allow_html=True)

            if st.session_state.conversation is None:
                text_chunks = df_gameinfo['ë³´ë“œê²Œì„ê°„ëµì†Œê°œ'].tolist() + df_cafeinfo['ì¹´í˜ê°„ëµì†Œê°œ'].tolist()
                vetorestore = get_vectorstore(text_chunks)
                st.session_state.conversation = get_conversation_chain(vetorestore, os.getenv("OPENAI_API_KEY"))

            for msg in st.session_state.messages:
                if msg["role"] == "user":
                    with st.chat_message("user"):
                        st.markdown(msg["content"])
                elif msg["role"] == "assistant":
                    with st.chat_message("assistant"):
                        st.markdown(msg["content"])

            if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
                st.session_state.messages.append({"role": "user", "content": query})
                with st.chat_message("user"):
                    st.markdown(query)

                found_game = None
                for game in df_gameinfo['ë³´ë“œê²Œì„ì´ë¦„'].tolist():
                    if game.lower() in query.lower():
                        found_game = game
                        break

                if found_game:
                    response = get_game_details(found_game)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    st.markdown(response, unsafe_allow_html=True)
                else:
                    with st.chat_message("assistant"):
                        if "ë³´ë“œê²Œì„" in query and "ì¶”ì²œ" in query and "ë³´ë“œê²Œì„ ì¹´í˜" not in query:
                            recommendation_response = handle_game_recommendation_from_csv(query)
                            for line in recommendation_response:
                                st.session_state.messages.append({"role": "assistant", "content": line})
                                st.markdown(line)
                        else:
                            chain = st.session_state.conversation
                            with st.spinner("Thinking..."):
                                result = chain({"question": query})
                                st.session_state.chat_history = result['chat_history']
                                chat_response = result['answer']
                                st.session_state.messages.append({"role": "assistant", "content": chat_response})
                                st.markdown(chat_response)

if __name__ == "__main__":
    main()
