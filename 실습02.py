import streamlit as st
import openai
import os
import pandas as pd
import random
from langchain.chains import ConversationalRetrievalChain
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.memory import ConversationBufferMemory
from langchain.vectorstores import FAISS
from langchain.schema import Document
from langchain.chat_models import ChatOpenAI

# API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = st.secrets["openai"]["api_key"]

# ì¶”ì²œìš© ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df_games = pd.read_csv('boardgames.csv')
df_cafes = pd.read_csv('cafes.csv')

# RAG ì±—ë´‡ìš© ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df_gameinfo = pd.read_csv('gameinfo.csv')
df_cafeinfo = pd.read_csv('cafeinfo.csv')

# ì´ˆê¸° ìƒíƒœ ì„¤ì •
def init_session_state():
    if "conversation" not in st.session_state:
        st.session_state.conversation = None
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = None
    if "processComplete" not in st.session_state:
        st.session_state.processComplete = None
    if 'messages' not in st.session_state:
        st.session_state['messages'] = [{"role": "assistant", 
                                         "content": "ì•ˆë…•í•˜ì„¸ìš”! ì£¼ì–´ì§„ ë¬¸ì„œì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹  ê²ƒì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë´ì£¼ì„¸ìš”!"}]

# ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
def get_vectorstore(text_chunks):
    documents = [Document(page_content=chunk) for chunk in text_chunks]
    embeddings = HuggingFaceEmbeddings(
        model_name="jhgan/ko-sroberta-multitask",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    vectordb = FAISS.from_documents(documents, embeddings)
    return vectordb

# ëŒ€í™” ì²´ì¸ ìƒì„±
def get_conversation_chain(vetorestore, openai_api_key):
    llm = ChatOpenAI(openai_api_key=openai_api_key, model_name='gpt-3.5-turbo', temperature=0)

    if "chat_memory" not in st.session_state:
        st.session_state.chat_memory = ConversationBufferMemory(
            memory_key='chat_history',
            return_messages=True,
            output_key='answer'
        )

    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm,
        chain_type="stuff",
        retriever=vetorestore.as_retriever(search_type='similarity', verbose=True),
        memory=st.session_state.chat_memory,
        get_chat_history=lambda h: h,
        return_source_documents=True,
        verbose=True
    )
    return conversation_chain

# ë³´ë“œê²Œì„ ì¶”ì²œ í•¨ìˆ˜
def show_recommended_games(genre):
    filtered_games = df_games[df_games['ì¥ë¥´'].str.contains(genre, na=False)]['ê²Œì„ ì´ë¦„'].tolist()
    random.shuffle(filtered_games)
    return filtered_games[:5]

# ë³´ë“œê²Œì„ ì¶”ì²œ ì²˜ë¦¬ í•¨ìˆ˜
def handle_game_recommendation_from_csv(query):
    if "ë³´ë“œê²Œì„" in query and "ì¶”ì²œ" in query and "ë³´ë“œê²Œì„ ì¹´í˜" not in query:
        # CSV íŒŒì¼ì—ì„œ ìƒˆë¡œìš´ ë³´ë“œê²Œì„ ì¶”ì²œ
        all_games = df_gameinfo['ë³´ë“œê²Œì„ì´ë¦„'].tolist()
        if all_games:
            recommended_games = random.sample(all_games, min(5, len(all_games)))
            # ê° í•­ëª© ì•ì— â—¾ë¥¼ ì¶”ê°€í•˜ê³  ì¤„ë°”ê¿ˆ ì²˜ë¦¬
            recommendation_response = "ì¶”ì²œí•  ìˆ˜ ìˆëŠ” ë³´ë“œê²Œì„ ëª©ë¡ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n" + "\n".join([f"â—¾ {game}" for game in recommended_games])
        else:
            recommendation_response = "í˜„ì¬ ë³´ë“œê²Œì„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    else:
        recommendation_response = "ì§ˆë¬¸ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”."
    return recommendation_response


# ë©”ì¸ í•¨ìˆ˜
def main():
    init_session_state()

    st.title("ë³´ë“œê²Œì„ ì¶”ì²œ ì‹œìŠ¤í…œ")
    st.subheader("ì›í•˜ì‹œëŠ” ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("ğŸ² ë³´ë“œê²Œì„ ì¶”ì²œ"):
            st.session_state.service = 'game_recommendation'
    with col2:
        if st.button("ğŸ  ë³´ë“œê²Œì„ ì¹´í˜ ì¶”ì²œ"):
            st.session_state.service = 'cafe_recommendation'
    with col3:
        if st.button("ğŸ§š ë³´ë“œê²Œì„ ìš”ì •ì—ê²Œ ì§ˆë¬¸í•˜ê¸°"):
            st.session_state.service = 'chat_with_fairy'

    if 'service' in st.session_state:
        if st.session_state.service == 'game_recommendation':
            st.subheader("ì–´ë– í•œ ì¥ë¥´ì˜ ë³´ë“œê²Œì„ì„ ì°¾ìœ¼ì‹œë‚˜ìš”?")
            genre = st.selectbox("ì¥ë¥´ ì„ íƒ", ['ë§ˆí”¼ì•„', 'ìˆœë°œë ¥', 'íŒŒí‹°', 'ì „ëµ', 'ì¶”ë¦¬', 'í˜‘ë ¥'])
            if genre:
                st.write("ë‹¤ìŒ ë³´ë“œê²Œì„ë“¤ì„ ì¶”ì²œí•©ë‹ˆë‹¤:")
                recommended_games = show_recommended_games(genre)
                st.write("\n".join(recommended_games))

        elif st.session_state.service == 'cafe_recommendation':
            st.subheader("ì–´ë””ì—ì„œ í•˜ì‹¤ ì˜ˆì •ì¸ê°€ìš”?")
            location = st.selectbox("ì§€ì—­ ì„ íƒ", ['í™ëŒ€', 'ì‹ ì´Œ', 'ê±´ëŒ€ì…êµ¬', 'ì´ìˆ˜', 'ê°•ë‚¨ì—­', 'ë¶€ì²œ'])
            if location:
                st.write("ë‹¤ìŒ ì¹´í˜ë“¤ì„ ì¶”ì²œí•©ë‹ˆë‹¤:")
                cafes = show_recommended_cafes(location)
                for cafe in cafes:
                    cafe_data = df_cafes[df_cafes['ì¹´í˜ ì´ë¦„'] == cafe].iloc[0]
                    review_count = cafe_data['ë°©ë¬¸ìë¦¬ë·°ìˆ˜']
                    naver_map_url = cafe_data['ë„¤ì´ë²„ì§€ë„ì£¼ì†Œ']
                    st.write(f"- {cafe} (ë°©ë¬¸ìë¦¬ë·°: {review_count}) ")
                    st.markdown(f"[â¡ï¸ ë„¤ì´ë²„ ì§€ë„]({naver_map_url})", unsafe_allow_html=True)

        elif st.session_state.service == 'chat_with_fairy':
            st.subheader("ë³´ë“œê²Œì„ ìš”ì •ì—ê²Œ ì§ˆë¬¸í•˜ê¸°")

            if st.session_state.conversation is None:
                text_chunks = df_gameinfo['ë³´ë“œê²Œì„ê°„ëµì†Œê°œ'].tolist() + df_cafeinfo['ì¹´í˜ê°„ëµì†Œê°œ'].tolist()
                vetorestore = get_vectorstore(text_chunks)
                st.session_state.conversation = get_conversation_chain(vetorestore, os.getenv("OPENAI_API_KEY"))

            if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
                st.session_state.messages.append({"role": "user", "content": query})
                with st.chat_message("user"):
                    st.markdown(query)

                with st.chat_message("assistant"):
                    if "ë³´ë“œê²Œì„" in query and "ì¶”ì²œ" in query and "ë³´ë“œê²Œì„ ì¹´í˜" not in query:
                        recommendation_response = handle_game_recommendation_from_csv(query)
                        st.markdown(recommendation_response)
                    else:
                        chain = st.session_state.conversation
                        with st.spinner("Thinking..."):
                            result = chain({"question": query})
                            st.session_state.chat_history = result['chat_history']
                            chat_response = result['answer']
                        st.markdown(chat_response)

if __name__ == "__main__":
    main()
