import streamlit as st
import openai
import os
import pandas as pd
import random
from langchain.chains import ConversationalRetrievalChain
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.memory import ConversationBufferMemory
from langchain.vectorstores import FAISS
from langchain.chat_models import ChatOpenAI
from langchain.schema import Document


# API í‚¤ ì„¤ì •
os.environ["OPENAI_API_KEY"] = st.secrets["openai"]["api_key"]

# ì¶”ì²œìš© ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df_games = pd.read_csv('boardgames.csv')
df_cafes = pd.read_csv('cafes.csv')

# RAG ì±—ë´‡ìš© ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
df_gameinfo = pd.read_csv('gameinfo.csv')
# df_cafeinfo = pd.read_csv('cafeinfo.csv')

# ì´ˆê¸° ìƒíƒœ ì„¤ì •
def init_session_state():
    if "conversation" not in st.session_state:
        st.session_state.conversation = None
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = None
    if "processComplete" not in st.session_state:
        st.session_state.processComplete = None
    if 'messages' not in st.session_state:
        st.session_state['messages'] = [{"role": "assistant", 
                                         "content": "ì•ˆë…•í•˜ì„¸ìš”! ì£¼ì–´ì§„ ë¬¸ì„œì— ëŒ€í•´ ê¶ê¸ˆí•˜ì‹  ê²ƒì´ ìˆìœ¼ë©´ ì–¸ì œë“  ë¬¼ì–´ë´ì£¼ì„¸ìš”!"}]

# ë²¡í„°ìŠ¤í† ì–´ ìƒì„±
def get_vectorstore(text_chunks):
    # Document ê°ì²´ë¡œ í…ìŠ¤íŠ¸ ì²­í¬ ë³€í™˜
    documents = [Document(page_content=chunk) for chunk in text_chunks]

    embeddings = HuggingFaceEmbeddings(
        model_name="jhgan/ko-sroberta-multitask",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    vectordb = FAISS.from_documents(documents, embeddings)
    return vectordb

# ëŒ€í™” ì²´ì¸ ìƒì„±
def get_conversation_chain(vetorestore, openai_api_key):
    llm = ChatOpenAI(openai_api_key=openai_api_key, model_name='gpt-3.5-turbo', temperature=0)
    conversation_chain = ConversationalRetrievalChain.from_llm(
        llm=llm, 
        chain_type="stuff", 
        retriever=vetorestore.as_retriever(search_type='mmr', verbose=True), 
        memory=ConversationBufferMemory(memory_key='chat_history', return_messages=True, output_key='answer'),
        get_chat_history=lambda h: h,
        return_source_documents=True,
        verbose=True
    )
    return conversation_chain

# ë³´ë“œê²Œì„ ì¶”ì²œ í•¨ìˆ˜
def show_recommended_games(genre):
    filtered_games = df_games[df_games['ì¥ë¥´'].str.contains(genre, na=False)]['ê²Œì„ ì´ë¦„'].tolist()
    random.shuffle(filtered_games)
    return filtered_games[:5]

# ì¹´í˜ ì¶”ì²œ í•¨ìˆ˜
def show_recommended_cafes(location):
    filtered_cafes = df_cafes[df_cafes['ì§€ì—­'].str.contains(location, na=False)]['ì¹´í˜ ì´ë¦„'].tolist()
    random.shuffle(filtered_cafes)
    return filtered_cafes[:5]

# ë©”ì¸ í•¨ìˆ˜
def main():
    init_session_state()

    st.title("ë³´ë“œê²Œì„ ì¶”ì²œ ì‹œìŠ¤í…œ")
    st.subheader("ì›í•˜ì‹œëŠ” ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("ğŸ² ë³´ë“œê²Œì„ ì¶”ì²œ"):
            st.session_state.service = 'game_recommendation'
    with col2:
        if st.button("ğŸ  ë³´ë“œê²Œì„ ì¹´í˜ ì¶”ì²œ"):
            st.session_state.service = 'cafe_recommendation'
    with col3:
        if st.button("ğŸ§š ë³´ë“œê²Œì„ ìš”ì •ì—ê²Œ ì§ˆë¬¸í•˜ê¸°"):
            st.session_state.service = 'chat_with_fairy'

    if 'service' in st.session_state:
        if st.session_state.service == 'game_recommendation':
            st.subheader("ì–´ë– í•œ ì¥ë¥´ì˜ ë³´ë“œê²Œì„ì„ ì°¾ìœ¼ì‹œë‚˜ìš”?")
            genre = st.selectbox("ì¥ë¥´ ì„ íƒ", ['ë§ˆí”¼ì•„', 'ìˆœë°œë ¥', 'íŒŒí‹°', 'ì „ëµ', 'ì¶”ë¦¬', 'í˜‘ë ¥'])
            if genre:
                st.write("ë‹¤ìŒ ë³´ë“œê²Œì„ë“¤ì„ ì¶”ì²œí•©ë‹ˆë‹¤:")
                games = show_recommended_games(genre)
                for game in games:
                    st.write(f"- {game}")

        elif st.session_state.service == 'cafe_recommendation':
            st.subheader("ì–´ë””ì—ì„œ í•˜ì‹¤ ì˜ˆì •ì¸ê°€ìš”?")
            location = st.selectbox("ì§€ì—­ ì„ íƒ", ['í™ëŒ€', 'ì‹ ì´Œ', 'ê±´ëŒ€ì…êµ¬', 'ì´ìˆ˜', 'ê°•ë‚¨ì—­', 'ë¶€ì²œ'])
            if location:
                st.write("ë‹¤ìŒ ì¹´í˜ë“¤ì„ ì¶”ì²œí•©ë‹ˆë‹¤:")
                cafes = show_recommended_cafes(location)
                for cafe in cafes:
                    cafe_data = df_cafes[df_cafes['ì¹´í˜ ì´ë¦„'] == cafe].iloc[0]
                    review_count = cafe_data['ë°©ë¬¸ìë¦¬ë·°ìˆ˜']
                    naver_map_url = cafe_data['ë„¤ì´ë²„ì§€ë„ì£¼ì†Œ']
                    st.write(f"- {cafe} (ë°©ë¬¸ìë¦¬ë·°: {review_count}) ")
                    st.markdown(f"[â¡ï¸ ë„¤ì´ë²„ ì§€ë„]({naver_map_url})", unsafe_allow_html=True)

        elif st.session_state.service == 'chat_with_fairy':
            st.subheader("ë³´ë“œê²Œì„ ìš”ì •ì—ê²Œ ì§ˆë¬¸í•˜ê¸°")

            # ëŒ€í™” ì²´ì¸ ì„¤ì •
            if st.session_state.conversation is None:
                # í•„ìš”í•œ í…ìŠ¤íŠ¸ ì²­í¬ë¥¼ ë¬¸ì„œí™”
                text_chunks = df_gameinfo['ë³´ë“œê²Œì„ê°„ëµì†Œê°œ'].tolist() + df_cafeinfo['ì¹´í˜ ì´ë¦„'].tolist()
                vetorestore = get_vectorstore(text_chunks)
                st.session_state.conversation = get_conversation_chain(vetorestore, os.getenv("OPENAI_API_KEY"))

            # ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥ ë° ëŒ€í™”
            if query := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."):
                st.session_state.messages.append({"role": "user", "content": query})
                with st.chat_message("user"):
                    st.markdown(query)

                with st.chat_message("assistant"):
                    chain = st.session_state.conversation

                    with st.spinner("Thinking..."):
                        result = chain({"question": query})
                        st.session_state.chat_history = result['chat_history']
                        response = result['answer']
                        source_documents = result['source_documents']
                        st.markdown(response)

if __name__ == "__main__":
    main()

